{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f1f306-1aa9-460a-9b20-29ceec3a8967",
   "metadata": {},
   "source": [
    "# Text Prediction AI Model Training\r\n",
    "This notebook will guide you through the process of training a text prediction AI model using GPT-2.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c3a2e0-b5c3-4d71-9488-29544a573467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: transformers in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: filelock in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas transformers torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e23b00-a622-42d0-a99a-16a40bfe9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())  \u001b[38;5;66;03m# Should return True if CUDA is available\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())  \u001b[38;5;66;03m# Should return the number of available GPUs\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/text_prediction/lib/python3.8/site-packages/torch/cuda/__init__.py:414\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/anaconda3/envs/text_prediction/lib/python3.8/site-packages/torch/cuda/__init__.py:444\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/anaconda3/envs/text_prediction/lib/python3.8/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.cuda.device_count())  # Should return the number of available GPUs\n",
    "print(torch.cuda.get_device_name(0))  # Should return the name of the first GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fcb6a6e-fb28-4d47-980b-4a5247769caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"dataset/ted_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0202f54-32be-4d51-a0a7-0b9de4bab134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean the transcript text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\(Laughter\\)', '', text)  # Remove \"(Laughter)\"\n",
    "    text = re.sub(r'\\(Music:.*?\\)', '', text)  # Remove \"(Music: ...)\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = text.strip()  # Remove leading and trailing spaces\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'transcript' column\n",
    "data['cleaned_transcript'] = data['transcript'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed4efa8-c0af-4b93-a017-162ea776a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding token: <|endoftext|>, ID: 50256\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer (replace 'model-name' with the actual model name you are using)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')  # Example model name\n",
    "\n",
    "# Set a padding token, you can use the end-of-sequence token or any other appropriate token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Verify that the pad_token is set\n",
    "print(f\"Padding token: {tokenizer.pad_token}, ID: {tokenizer.pad_token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd47c7d0-ab01-4fc1-8468-3ea115640a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize the text\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Apply the tokenization function to the 'cleaned_transcript' column\n",
    "data['tokenized'] = data['cleaned_transcript'].apply(tokenize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb9d325-c11a-4272-8f40-3c1e1b61f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  cleaned_transcript  \\\n",
      "0  Good morning. How are you?It's been great, has...   \n",
      "1  Thank you so much, Chris. And it's truly a gre...   \n",
      "2  Hello voice mail, my old friend.I've called fo...   \n",
      "3  If you're here today â€” and I'm very happy that...   \n",
      "4  About 10 years ago, I took on the task to teac...   \n",
      "\n",
      "                     tokenized  \n",
      "0  [input_ids, attention_mask]  \n",
      "1  [input_ids, attention_mask]  \n",
      "2  [input_ids, attention_mask]  \n",
      "3  [input_ids, attention_mask]  \n",
      "4  [input_ids, attention_mask]  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the tokenized data\n",
    "print(data[['cleaned_transcript', 'tokenized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c983a3-eaa7-4efe-aedd-41ae3390342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and tokenized data to a new CSV file (optional)\n",
    "data.to_csv('dataset/cleaned_tokenized_ted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719d8f4d-d000-4b38-b7a6-3f826000433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Load the cleaned and tokenized data\n",
    "data = pd.read_csv('dataset/cleaned_tokenized_ted_data.csv')\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f815e1f-7653-4017-925f-d1ad1a253861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (0.32.1)\n",
      "Requirement already satisfied: transformers[torch] in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (4.42.3)\n",
      "Requirement already satisfied: filelock in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: psutil in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50cb5109-fa22-4c1e-a8c9-0a854053dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.21.0\n",
      "  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate==0.21.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate==0.21.0) (24.1)\n",
      "Requirement already satisfied: psutil in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate==0.21.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate==0.21.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate==0.21.0) (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch>=1.10.0->accelerate==0.21.0) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
      "Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.32.1\n",
      "    Uninstalling accelerate-0.32.1:\n",
      "      Successfully uninstalled accelerate-0.32.1\n",
      "Successfully installed accelerate-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U 'accelerate==0.21.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c88752-c3f9-4480-ac64-b65c5f55ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained model (replace 'model-name' with the actual model name you are using)\n",
    "model_name = 'gpt2'  # Example model name\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',           # output directory\n",
    "    overwrite_output_dir=True,        # overwrite the content of the output directory\n",
    "    num_train_epochs=3,               # number of training epochs\n",
    "    per_device_train_batch_size=2,    # batch size for training\n",
    "    save_steps=10_000,                # save checkpoint every 10,000 steps\n",
    "    save_total_limit=2,               # only keep the last 2 checkpoints\n",
    "    logging_dir='./logs',             # directory for storing logs\n",
    "    logging_steps=200,                # log every 200 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bbde4d2-7675-43c7-a1dd-e2f0013a29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Define the data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We are not using masked language modeling for GPT-2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d50cb5-2f7f-479a-8076-74540646db9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2bee78639342f1994b02000ee788c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map inputs to the required format\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['cleaned_transcript'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['transcript', 'url', 'cleaned_transcript'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9843018-8d1d-4a04-9e76-bf5c579607b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.32.1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "\n",
    "accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8606e9e8-5b24-4a4b-be0c-06e6dd915e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: accelerate in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (0.21.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: datasets in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (2.20.0)\n",
      "Requirement already satisfied: transformers[torch] in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (4.42.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: filelock in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from transformers[torch]) (2.3.1)\n",
      "Requirement already satisfied: psutil in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from requests->transformers[torch]) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/master/anaconda3/envs/text_prediction/lib/python3.8/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "Successfully installed accelerate-0.32.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas transformers[torch] accelerate -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd0726a-c4f2-4f59-b2a2-4f908467b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained model (replace 'model-name' with the actual model name you are using)\n",
    "model_name = 'gpt2'  # Example model name\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',           # output directory\n",
    "    overwrite_output_dir=True,        # overwrite the content of the output directory\n",
    "    num_train_epochs=3,               # number of training epochs\n",
    "    per_device_train_batch_size=2,    # batch size for training\n",
    "    save_steps=10_000,                # save checkpoint every 10,000 steps\n",
    "    save_total_limit=2,               # only keep the last 2 checkpoints\n",
    "    logging_dir='./logs',             # directory for storing logs\n",
    "    logging_steps=200,                # log every 200 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4397b523-b370-4935-ac88-243f98292682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Define the data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We are not using masked language modeling for GPT-2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "353743e4-3081-443c-95ba-edbe917023e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7549d29ab5ba4e138547aab967a73c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map inputs to the required format\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['cleaned_transcript'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['transcript', 'url', 'cleaned_transcript'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993ec24-b632-4a9a-94b8-c51d84f739c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
